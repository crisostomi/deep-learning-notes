%!TEX root = ../root.tex

\emph{Adversarial machine learning} is an umbrella term that refers to a class of methods that, with different motivations, seek to fool models by supplying deceptive input.

This can be done to test the robustness of a model, to probe the level of understanding the network has of the underlying task, by looking at the error rate on examples that are intentionally constructed to be difficult to process by the model, called \emph{adversarial examples}. 
These examples are generated by using an optimization procedure to search for an input $x'$ near a data point $x$ such that the model output is very different at $x'$. In many cases, $x'$ can be so similar to $x$ that a human observer cannot tell the difference between the original example and the adversarial example, but the network can make highly different predictions.

On the other hand, one can perform \emph{adversarial training}, that involves two models being trained \emph{in competition} with each other, i.e. as \emph{adversaries}. This is the topic on which we will focus.

\section{Generative Adversarial Networks} 
\input{13_Adversarial/13.1_GAN/content.tex}
\section{Adversarial attacks} 
\input{13_Adversarial/13.2_Adversarial_attacks/content.tex}
