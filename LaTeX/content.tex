%!TEX root=./root.tex

\begin{document}

\maketitle

\section*{Disclaimer and acknowledgments}
This document served as my personal course notes when I took the course in A.Y. 19/20; if I will have time, I will try to update it to reflect the more recent material seen throughout the course. 
Most of the material comes from the course lectures held by Prof. E. Rodol√†, with some additions here and there.
The document is not guaranteed to be error-free, and should always be taken \textit{cum grano salis}. Please reach out to me to report errors and/or problems.
  
A special thanks to S. Antonelli, G. Attenni, A. Caciolai and S. Esposito who helped me to draw up these notes.

\tableofcontents

\chapter{Data} 
\input{02_Data/content.tex}

\chapter{Linear regression, convexity and gradients}
\input{04_Lin_reg/content.tex}

\chapter{Nonlinear models, overfitting and regularization}
\input{05_Nonlinear/content.tex}

\chapter{Stochastic gradient descent} 
\input{06_Gradient/content.tex}

\chapter{Multi-layer perceptron and back-propagation} 
\input{07_MLP/content.tex}

\chapter{Convolutional neural networks} 
\input{08_CNN/content.tex}

\chapter{Regularization} 
\input{09_Regularization/content.tex}

\chapter{Deep generative models} 
\input{11_Generative/content.tex}

\chapter{Geometric deep learning} 
\input{12_Gdl/content.tex}

\chapter{Adversarial training} 
\input{13_Adversarial/content.tex}

% \chapter{Transformers}
% \input{14_Transformers/content.tex}

\appendix

\chapter{Linear Algebra} 
\input{A_Lin_alg/content.tex}
\chapter{Information Theory} \label{sec:appendix-A}
\input{Entropy/content.tex}
\chapter{Fourier Analysis} \label{sec:appendix:fourier}
\input{Fourier/content.tex}
\chapter{Spectral Graph Theory} 
\input{D_Graph_Spectral_theory/content.tex}
\end{document}